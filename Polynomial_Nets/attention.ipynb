{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from polynomial_nets import CP_L3, CP_L3_sparse\n",
    "\n",
    "from poly_VAE import Flatten, UnFlatten, VAE_CP_L3, VAE_CP_L3_sparse, VAE_CP_L3_sparse_LU, loss_fn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Construct the conv layers\n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        \n",
    "        # Initialize gamma as 0\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax  = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B * C * W * H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B * N * N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        \n",
    "        proj_query  = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0,2,1) # B * N * C\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        energy =  torch.bmm(proj_query, proj_key) # batch matrix-matrix product\n",
    "        \n",
    "        attention = self.softmax(energy) # B * N * N\n",
    "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "        out = torch.bmm(proj_value, attention.permute(0,2,1)) # batch matrix-matrix product\n",
    "        out = out.view(m_batchsize,C,width,height) # B * C * W * H\n",
    "        \n",
    "        # Add attention weights onto input\n",
    "        out = self.gamma*out + x\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 10\n",
    "height = 10\n",
    "in_dim = 6\n",
    "m_batchsize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = nn.Parameter(torch.zeros(1))\n",
    "softmax  = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//2 , kernel_size= 1)\n",
    "value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = query_conv.weight.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(m_batchsize, in_dim, width, height)\n",
    "m_batchsize,C,width ,height = x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = query_conv(x)\n",
    "output2 = value_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_query  = query_conv(x).view(m_batchsize, -1, width*height).permute(0,2,1)\n",
    "proj_key =  key_conv(x).view(m_batchsize, -1, width*height) # B * C * N\n",
    "energy =  torch.bmm(proj_query, proj_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100, 3]) torch.Size([5, 3, 100]) torch.Size([5, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "print(proj_query.shape, proj_key.shape, energy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6, 100]) torch.Size([5, 100, 100])\n",
      "torch.Size([5, 6, 100])\n",
      "torch.Size([5, 6, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "attention = softmax(energy) # B * N * N\n",
    "proj_value = value_conv(x).view(m_batchsize, -1, width*height)\n",
    "print(proj_value.shape, attention.shape) # B * C * N\n",
    "out = torch.bmm(proj_value, attention.permute(0,2,1)) # batch matrix-matrix product\n",
    "print(out.shape)\n",
    "\n",
    "out1 = out.view(m_batchsize,C,width,height)\n",
    "print(out1.shape) # B * C * W * H\n",
    "\n",
    "# Add attention weights onto input\n",
    "out2 = gamma*out1 + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 100])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "input_size = 10\n",
    "rank = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(batch_size, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_q = nn.Linear(input_size, rank)\n",
    "U_k = nn.Linear(input_size, rank)\n",
    "U_v = nn.Linear(input_size, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = U_q(z)\n",
    "k = U_k(z)\n",
    "v = U_v(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = torch.bmm(q.unsqueeze(2), k.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_scaled = energy / rank ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = energy_scaled.softmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(attention, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.bmm(v.unsqueeze(1), attention.permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = attention @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5283, -0.0202,  0.4027, -0.2598,  0.0642],\n",
       "        [-0.5338,  0.0027,  0.3663, -0.1216,  0.1013],\n",
       "        [-0.5773,  0.0289,  0.4369, -0.3464,  0.0117]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out2 \u001b[39m=\u001b[39m gamma\u001b[39m*\u001b[39;49mout \u001b[39m+\u001b[39;49m z\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "out2 = gamma*out + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d, k, o):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.layer_U_q = nn.Linear(d, k, bias=False)\n",
    "        self.layer_U_k = nn.Linear(d, k, bias=False)\n",
    "        self.layer_U_v = nn.Linear(d, k, bias=False)\n",
    "\n",
    "        self.layer_C = nn.Linear(k, o)   \n",
    "        self.input_dimension = d \n",
    "        self.rank = k\n",
    "        self.output_dimension = o \n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.reshape(-1, self.input_dimension)\n",
    "        q = self.layer_U_q(z)\n",
    "        k = self.layer_U_k(z)\n",
    "        v = self.layer_U_v(z)\n",
    "        energy = torch.bmm(q.unsqueeze(2), k.unsqueeze(1)) / self.rank ** 0.5\n",
    "        attention = energy.softmax(dim = -1)\n",
    "        out = torch.bmm(v.unsqueeze(1), attention.permute(0,2,1))\n",
    "        \n",
    "        x = self.layer_C(out)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "542851ebc7f1b97dab2659843c1270f7c570d916e83d4380bfc02112104e2680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
